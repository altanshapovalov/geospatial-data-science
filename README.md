**READ FIRST:** brief descriptions of what each script in this repository contains; assignments 3-5 are more intricate.

**1. asgt1_shapovalov.ipynb** – use the most basic numpy commands, display different text styles (i.e., italicized, bold), and add a link to an image from the web. 

**2. asgt2_shapovalov.ipynb**– use geopandas to analyze datasets of spotted owls and wildfires. 1) Import necessary packages [i.e., geopandas], 2) extract the most basic information about datasets, 3) retroject a dataset, 4) perform quantitative analysis on the datasets, 5) merge different datasets, and 6) plot data for both datasets. 

**3. asgt3_shapovalov.ipynb** – use geopandas, osmnx, numpy, and networks python libraries to analyze network data. 1) Convert graphs to GeoDataFrames [osmnx], 2) determine the coordinate reference system, 3) produce a graph showing the network dataset, 4) read shapefile with data about cities [geopandas], 5) compute euclidean distances between selected cities, 6) identify nodes closest to each city, 7) plot and calculate shortest path between each city [networkx], 8) compare network and euclidean distances [numpy], and 9) determine travel time between cities with select speeds.  

**4. asgt4_shapovalov.ipynb** – use numpy, rasterio, pandas, xarray, and matplotlib python libraries to analyze land cover datasets and work with climate data. 0) Open land cover class data [rasterio], 1) list coordinate maximums, 2) plot land cover data [matplotlib], 3) count how many grid cells are certain land cover types [numpy], 4) aggregate developed land classes, 5) calculate percentage of certain land cover types relative to the entire dataset [pandas], 6) compare changes of land cover types through time, 7) open climate data stored in an .nc file [xarray], 8) determine temperatures at specific coordinates, and 9) find where highest temperatures existed on Earth for a given time. 

**5. asgt5_shapovalov.ipynb** – use numpy, pandas, matplotlib, and sklearn (StandardScaler, train_test_split, LinearRegression, mean_squared_error, DecisionTreeRegressor, RandomForestRegressor) to test out various machine learning models to predict house prices. 1) Import .csv file with dataset [pandas], 2) check for null values, 3) calculate correlations of different variables with house prices, 4) scale/normalize features before training a model, 5) split data into training and testing subsets, 6) perform multiple linear regression, 7) perform decision tree analysis, and 8) perform random forests algorithm.
